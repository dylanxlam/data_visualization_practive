{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdoSGJp1fRAX"
   },
   "source": [
    "# HWK6 Part 2: Geovisualization\n",
    "\n",
    "#### Name: Dylan Lam\n",
    "#### UT EID: DXL85\n",
    "\n",
    "#### Name: Eric Nguyen\n",
    "#### UT EID: edn447\n",
    "\n",
    "#### Date:\n",
    "\n",
    "In this portion of the homework we will be analyzing and visualizing geographic data; i.e., data that refers to geospatial entities. Geospatial entities can, for example, be particular places such as schools and libraries or political boundaries of cities or countries. Of course, this tutorial only scratches the surface. Consider this as a teaser into geovisualization, which in itself has become a branch of research and practice at the intersection of geography and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HAdaamMcGEwV"
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZMy4JBoF6Jp"
   },
   "source": [
    "### Install packages\n",
    "\n",
    "For this tutorial we will continue to rely on Altair and Pandas, but add **GeoPandas**, which will help us to work with DataFrames that contain spatial entities to carry out geometric analysis on them. As before, the pip install command is carried out via the shell, which is indicated by the exclamation mark at the beginning of the line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6oQAHqnRPK1z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-0.13.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting fiona>=1.8.19 (from geopandas)\n",
      "  Downloading fiona-1.10.1-cp38-cp38-macosx_11_0_arm64.whl.metadata (56 kB)\n",
      "Requirement already satisfied: packaging in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from geopandas) (24.1)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from geopandas) (2.0.3)\n",
      "Collecting pyproj>=3.0.1 (from geopandas)\n",
      "  Downloading pyproj-3.5.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting shapely>=1.7.1 (from geopandas)\n",
      "  Downloading shapely-2.0.6-cp38-cp38-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (24.2.0)\n",
      "Requirement already satisfied: certifi in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (2024.8.30)\n",
      "Requirement already satisfied: click~=8.0 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (8.1.7)\n",
      "Collecting click-plugins>=1.0 (from fiona>=1.8.19->geopandas)\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting cligj>=0.5 (from fiona>=1.8.19->geopandas)\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: importlib-metadata in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (8.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from pandas>=1.1.0->geopandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from pandas>=1.1.0->geopandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from pandas>=1.1.0->geopandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from pandas>=1.1.0->geopandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.0->geopandas) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from importlib-metadata->fiona>=1.8.19->geopandas) (3.20.2)\n",
      "Downloading geopandas-0.13.2-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fiona-1.10.1-cp38-cp38-macosx_11_0_arm64.whl (14.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyproj-3.5.0-cp38-cp38-macosx_11_0_arm64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.6-cp38-cp38-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Installing collected packages: shapely, pyproj, cligj, click-plugins, fiona, geopandas\n",
      "Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.10.1 geopandas-0.13.2 pyproj-3.5.0 shapely-2.0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_85h7Q7GKqa"
   },
   "source": [
    "To access the data of the OpenStreetMap, we will install the handy package **OSMPythonTools**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JKnM45BiGHSn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting OSMPythonTools\n",
      "  Downloading OSMPythonTools-0.3.5.tar.gz (28 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4 (from OSMPythonTools)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting geojson (from OSMPythonTools)\n",
      "  Downloading geojson-3.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting lxml (from OSMPythonTools)\n",
      "  Downloading lxml-5.3.0.tar.gz (3.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from OSMPythonTools) (3.7.2)\n",
      "Requirement already satisfied: numpy in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from OSMPythonTools) (1.24.3)\n",
      "Requirement already satisfied: pandas in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from OSMPythonTools) (2.0.3)\n",
      "Collecting ujson (from OSMPythonTools)\n",
      "  Downloading ujson-5.10.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (9.3 kB)\n",
      "Collecting xarray (from OSMPythonTools)\n",
      "  Downloading xarray-2023.1.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->OSMPythonTools)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from matplotlib->OSMPythonTools) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from matplotlib->OSMPythonTools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from matplotlib->OSMPythonTools) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from matplotlib->OSMPythonTools) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from matplotlib->OSMPythonTools) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from matplotlib->OSMPythonTools) (10.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from matplotlib->OSMPythonTools) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from matplotlib->OSMPythonTools) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from matplotlib->OSMPythonTools) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from pandas->OSMPythonTools) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from pandas->OSMPythonTools) (2024.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->OSMPythonTools) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dylanlam/miniconda3/envs/myenv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->OSMPythonTools) (1.16.0)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading geojson-3.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading ujson-5.10.0-cp38-cp38-macosx_11_0_arm64.whl (51 kB)\n",
      "Downloading xarray-2023.1.0-py3-none-any.whl (973 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.1/973.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: OSMPythonTools, lxml\n",
      "  Building wheel for OSMPythonTools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for OSMPythonTools: filename=OSMPythonTools-0.3.5-py3-none-any.whl size=32715 sha256=0555e408940582b48264b5354424fea05ed58684b9350849b9977e2fb8323de4\n",
      "  Stored in directory: /Users/dylanlam/Library/Caches/pip/wheels/dc/2e/0b/51582d4741d2847aa6b6cac475561cc83ee65337380d88fb8c\n",
      "  Building wheel for lxml (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lxml: filename=lxml-5.3.0-cp38-cp38-macosx_11_0_arm64.whl size=1556169 sha256=05e12c55ed06837202f426fc24440f654f8a2364cea6994d1865afa5291212d4\n",
      "  Stored in directory: /Users/dylanlam/Library/Caches/pip/wheels/37/19/50/80ff9642d74365e416a0b370a5784afd3167f4e1182644c30b\n",
      "Successfully built OSMPythonTools lxml\n",
      "Installing collected packages: ujson, soupsieve, lxml, geojson, beautifulsoup4, xarray, OSMPythonTools\n",
      "Successfully installed OSMPythonTools-0.3.5 beautifulsoup4-4.12.3 geojson-3.1.0 lxml-5.3.0 soupsieve-2.6 ujson-5.10.0 xarray-2023.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade OSMPythonTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3qDRjua8Yvz"
   },
   "source": [
    "Once we have the tools assembled, we can get started working with geospatial data. There are actually plenty of formats used to record geospatial data, but GeoJSON has become an important standard for exchanging geospatial data on the web. However, please note that GeoPandas can actually load many other vector-based data formats used in digital cartography, such as shapefiles and GeoPackage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LarBaT3QUDbg"
   },
   "source": [
    "### Import GeoJSON\n",
    "\n",
    "Suppose we would like to get the geographic boundaries of Austin's neighborhoods. Akin to how we would read a JSON file with Pandas, we can also use `read_file()` provided by GeoPandas simply by passing the geojson filename and get a geographic DataFrame back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eT05GlA_hVLf"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fiona' has no attribute 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m neighborhoods \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39;49mread_file(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://gist.githubusercontent.com/TieJean/40e9ccc69f0cc65b8e06ccf3fd60a3f0/raw/04ec5f998e63185e65f4d415827f1838ff8a25ab/austin.geojson\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/geopandas/io/file.py:281\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         path_or_bytes \u001b[39m=\u001b[39m filename\n\u001b[0;32m--> 281\u001b[0m     \u001b[39mreturn\u001b[39;00m _read_file_fiona(\n\u001b[1;32m    282\u001b[0m         path_or_bytes, from_bytes, bbox\u001b[39m=\u001b[39;49mbbox, mask\u001b[39m=\u001b[39;49mmask, rows\u001b[39m=\u001b[39;49mrows, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munknown engine \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mengine\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/geopandas/io/file.py:299\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mwhere requires fiona 1.9+\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    295\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m from_bytes:\n\u001b[1;32m    296\u001b[0m     \u001b[39m# Opening a file via URL or file-like-object above automatically detects a\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[39m# zipped file. In order to match that behavior, attempt to add a zip scheme\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[39m# if missing.\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mif\u001b[39;00m _is_zip(\u001b[39mstr\u001b[39;49m(path_or_bytes)):\n\u001b[1;32m    300\u001b[0m         parsed \u001b[39m=\u001b[39m fiona\u001b[39m.\u001b[39mparse_path(\u001b[39mstr\u001b[39m(path_or_bytes))\n\u001b[1;32m    301\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(parsed, fiona\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mParsedPath):\n\u001b[1;32m    302\u001b[0m             \u001b[39m# If fiona is able to parse the path, we can safely look at the scheme\u001b[39;00m\n\u001b[1;32m    303\u001b[0m             \u001b[39m# and update it to have a zip scheme if necessary.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/geopandas/io/file.py:166\u001b[0m, in \u001b[0;36m_is_zip\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_is_zip\u001b[39m(path):\n\u001b[1;32m    165\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check if a given path is a zipfile\"\"\"\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     parsed \u001b[39m=\u001b[39m fiona\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39mParsedPath\u001b[39m.\u001b[39mfrom_uri(path)\n\u001b[1;32m    167\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    168\u001b[0m         parsed\u001b[39m.\u001b[39marchive\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.zip\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    169\u001b[0m         \u001b[39mif\u001b[39;00m parsed\u001b[39m.\u001b[39marchive\n\u001b[1;32m    170\u001b[0m         \u001b[39melse\u001b[39;00m parsed\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.zip\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    171\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'fiona' has no attribute 'path'"
     ]
    }
   ],
   "source": [
    "neighborhoods = gpd.read_file(\"https://gist.githubusercontent.com/TieJean/40e9ccc69f0cc65b8e06ccf3fd60a3f0/raw/04ec5f998e63185e65f4d415827f1838ff8a25ab/austin.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eso0qtudC9OU"
   },
   "source": [
    "The main difference between a regular Pandas DataFrame is that a GeoDataFrame features a `geometry` column, which is a geoseries containing the points, paths, and polygons for each row. For example, if each row represents one neighborhood, the respective geometries would probably contain the geospatial boundaries…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxV1dVZ2CxOc"
   },
   "source": [
    "💡 *Are you curious what the neighborhoods dataframe actually looks like? Take a look at it with the methods you know by now:* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2Tl9r_eDYHE"
   },
   "outputs": [],
   "source": [
    "neighborhoods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMn9u2BHk8jR"
   },
   "source": [
    "Geographically speaking, the districts are defined by their geographic shapes, which are represented as polygons, each of which is a list of tuples of geographic coordinates. Next we add information about schools in Austin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFSHsubClAX7"
   },
   "outputs": [],
   "source": [
    "schools = gpd.read_file(\"https://gist.githubusercontent.com/TieJean/4e9f595eb3cb5dc60a960c3a499f6141/raw/171118ec54c599ce4bf9a30f9ab176427a47629f/austin_schools.geojson\")\n",
    "schools.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzQDMN0aNCpc"
   },
   "source": [
    "💡 *Have a look at the schools as well, and compare the contents of the `geometry` columns in schools and districts. Do you notice anything?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7XIn2vBUFf7"
   },
   "source": [
    "### Query OpenStreetMap\n",
    "\n",
    "OpenStreetMap (OSM) is \"a collaborative project to create a free editable map of the world\". As such it has millions of contributing users who have been collecting, updating and refining map data for over 15 years, which has generated a vastly comprehensive source of geographic data. It is by no means complete—whatever this would mean—but it is an impressively large geographic database and, of course, a map in itself, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFASROYGPYQ8"
   },
   "source": [
    "OpenStreetMap has its own kind of query language, which is quite compact and can also be a source for errors. To make query formulation easier, you can either use the web interface [overpass turbo](http://overpass-turbo.eu) or the `overpassQueryBuilder`, which provides access to the main parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-FOD9uqX_TQ"
   },
   "outputs": [],
   "source": [
    "from OSMPythonTools.overpass import overpassQueryBuilder\n",
    "\n",
    "AustinAreaID = 3600000000 + 113314\n",
    "# The area ID of a city is found by adding 3600000000 to the city's relation ID\n",
    "# You can look up the relation ID of any city by searching on the OSM website; for example, https://www.openstreetmap.org/relation/113314 \n",
    "\n",
    "library_query = overpassQueryBuilder(\n",
    "    area=AustinAreaID, # the query can be constrained by an area of an item\n",
    "    elementType='node', # which are points (OSM also has ways and relations)\n",
    "    # the selector in the next line is really the heart of the query:\n",
    "    selector='\"amenity\"=\"library\"', # we're looking for libraries\n",
    "    out='body', # body indicates that we want the data, not just the count\n",
    "    includeGeometry=True # and we want the geometric information, too\n",
    ")\n",
    "\n",
    "library_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uVssn6KQZPc"
   },
   "source": [
    "The output of above cell is the compact version of the query, which is carried out in the next step:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2g6225PY4hg"
   },
   "outputs": [],
   "source": [
    "from OSMPythonTools.overpass import Overpass\n",
    "overpass = Overpass()\n",
    "\n",
    "lib_data = overpass.query(library_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4pIbxpY3Qk9"
   },
   "source": [
    "The variable `lib_data` now already contains the result from the query against OSM. Let's have a look at it. With `nodes()` we can access the retrieved points. Let's take a look at the first entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksh3eymU2QqQ"
   },
   "outputs": [],
   "source": [
    "lib_data.nodes()[0].tags()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEW2uLK_4GbJ"
   },
   "source": [
    "Similarly, we can also access the geometry, which in this case is just a point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1f3uZpZ6cNM"
   },
   "outputs": [],
   "source": [
    "lib_data.nodes()[0].geometry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gljn6riv6jrb"
   },
   "source": [
    "Next, we use the compact form of a list comprehension to extract the libraries' names and coordinates:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFMNsQ_A14ZJ"
   },
   "outputs": [],
   "source": [
    "libraries = [ (lib.tag(\"name\"), lib.geometry() ) for lib in lib_data.nodes()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3n2W8J_CT3T8"
   },
   "source": [
    "… which we turn into a GeoDataFrame. By naming the second column `geometry` we indicate towards GeoPandas to interpret the coordinates as geographic locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8QZQeNkO5in"
   },
   "outputs": [],
   "source": [
    "libraries = gpd.GeoDataFrame(libraries, columns = ['name', 'geometry'])\n",
    "libraries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mY9BwcoLbDIc"
   },
   "source": [
    "## 🗺  Present\n",
    "\n",
    "When we have geospatial data readily available as GeoDataFrames, we can now map them with Altair. \n",
    "\n",
    "(There are other mapping libraries for Python, such as [Folium](https://python-visualization.github.io/folium/), that provide additional functionalities. Altair's geovis features are basic, but do provide some variety of techniques and have the benefit to work consistently with the other chart types we covered.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-uzzuL45HLB"
   },
   "source": [
    "### Markers on maps\n",
    "\n",
    "A simple start is placing locations on a base map and adding a bit of further information via tooltips. Let's do this with Austin's schools! First, we can have another look at the attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUhFcvcfgNYn"
   },
   "outputs": [],
   "source": [
    "schools.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uM4Ap_r88tWX"
   },
   "source": [
    "We will now create a simple map with markers in the form of an  Altair chart consisting of two layers:\n",
    "\n",
    "1.   The `neighborhoods` form the lower layer representing their boundaries and the overall geographic shape of Austin\n",
    "2.   The `schools` are the points of interests that are displayed on top\n",
    "\n",
    "When putting the two layers together they should actually refer to the same geographic location to make sense. Here the neighborhoods and schools both refer to Austin. Also note that the order when the charts are added together determines the vertical order: first the basemap and then markers on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGwFliinde0W"
   },
   "outputs": [],
   "source": [
    "# 1.  mark_geoshape transparently uses the geometry column\n",
    "basemap = alt.Chart(neighborhoods).mark_geoshape(\n",
    "    # add some styling to reduce the salience of the basemap\n",
    "    fill=\"lightgray\", stroke=\"darkgray\",\n",
    ").encode(\n",
    "    tooltip = ['name'],\n",
    ").properties(width=600, height=600)\n",
    "\n",
    "# 2.  we use mark_circle to have more control over visual variables\n",
    "markers = alt.Chart(schools).mark_circle(opacity=1).encode(\n",
    "    # point latitude & longitude to coordinates in geometry column\n",
    "    longitude='geometry.coordinates[0]:Q',\n",
    "    latitude='geometry.coordinates[1]:Q',\n",
    "    tooltip=['NAME', 'STREET', 'ZIP'],\n",
    ")\n",
    "\n",
    "# combine the two layers \n",
    "basemap + markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raDgI4sgrOli"
   },
   "source": [
    "### Dot density maps\n",
    "\n",
    "Let's use the open maps data set again, and plot New York's trees. Note, we will have to disable the max rows since there are more than 5,000 trees returned from the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5Cfw9q91_M2"
   },
   "outputs": [],
   "source": [
    "NewYorkCityAreaID = 3600000000 + 175905\n",
    "\n",
    "# 1. prepare query (and directly include the location lookup)\n",
    "tree_query = overpassQueryBuilder(\n",
    "    area=NewYorkCityAreaID,\n",
    "    elementType='node',\n",
    "    selector='\"natural\"=\"tree\"', \n",
    "    out='body', \n",
    "    includeGeometry=True\n",
    ")\n",
    "\n",
    "# 2. execute query (and give it a bit more time to finish)\n",
    "tree_data = overpass.query(tree_query, timeout=60)\n",
    "\n",
    "# 3. get ids and coordinates of trees\n",
    "tree_locs = [ (tree.id(), tree.geometry()) for tree in tree_data.nodes()]\n",
    "\n",
    "# 4. create GeoDataFrame\n",
    "trees = gpd.GeoDataFrame(tree_locs, columns=[\"id\", \"geometry\"])\n",
    "\n",
    "trees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3j53kKVqA1Ab"
   },
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()\n",
    "treemap = alt.Chart(trees).mark_circle(\n",
    "    # reduce the visual presence of each element\n",
    "    size=5,\n",
    "    # with a low dot opacity we can use overplotting to indicate densities\n",
    "    opacity=.25,\n",
    "    # a natural choice\n",
    "    color=\"green\"\n",
    ").encode(\n",
    "    longitude='geometry.coordinates[0]:Q', \n",
    "    latitude='geometry.coordinates[1]:Q'    \n",
    ").properties(width=600, height=600)\n",
    "\n",
    "treemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkOl6xBbpcvg"
   },
   "source": [
    "### Choropleth maps\n",
    "\n",
    "Finally, let's create the geovisualization that uses the fill color of geospatial shapes to encode quantitative data. To illustrate this, we will visualize the population densities around the world. We will use area and population information from GeoNames and get the geographic shapes of countries from a geojson file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycbrILMypgKZ"
   },
   "outputs": [],
   "source": [
    "# load country data from geonames CSV\n",
    "geonames = pd.read_csv(\"./countryInfoCSV.csv\", sep='\\t')\n",
    "# select four columns\n",
    "geonames = geonames[['name', 'iso alpha3', 'areaInSqKm', 'population']]\n",
    "# set index to country code\n",
    "geonames = geonames.set_index(\"iso alpha3\")\n",
    "\n",
    "geonames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6l_Ku_wW1lh6"
   },
   "source": [
    "Next we collect the geographic boundaries and `simplify` them a bit, as they have more detail than what we need here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHMzJNCzqC4o"
   },
   "outputs": [],
   "source": [
    "# load country's polygons from datahub\n",
    "polygons = gpd.read_file(\"https://gist.githubusercontent.com/TieJean/f739f67075108868059b101a709a738f/raw/cb358884e028658993c2da1dfd19854e6c5b6c3b/countries.geo.json\")\n",
    "# remove country names, as we have them already\n",
    "polygons = polygons.drop(columns=[\"name\"])\n",
    "# set index to country code\n",
    "polygons = polygons.set_index(\"id\")\n",
    "# reduce the complexity of the shapes\n",
    "polygons.geometry = polygons.geometry.simplify(.1)\n",
    "\n",
    "polygons.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LV4sMlOtx_p2"
   },
   "source": [
    "As both DataFrames use the three-letter country codes as indices we can join them like this (join uses the index by default, so we don't have to specify what to join on):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJHEiiHIr79i"
   },
   "outputs": [],
   "source": [
    "# inner means that we keep only those countries\n",
    "# for which we have geometric and attribute data\n",
    "countries = polygons.join(geonames, how='inner')\n",
    "\n",
    "countries.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4x3FbytP1-ja"
   },
   "source": [
    "Visualizing area or population in a choropleth map, arguably, makes little sense. So let's compute population densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqEjsq_z0nVc"
   },
   "outputs": [],
   "source": [
    "countries[\"density\"] = countries[\"population\"] / countries[\"areaInSqKm\"]\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmR73ddX6gMb"
   },
   "source": [
    "Keep only those countries with valid density value and turn these densities into integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dA8GyDFC6iN3"
   },
   "outputs": [],
   "source": [
    "countries = countries[countries['density'].notna()]\n",
    "countries.density = countries.density.round(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z63gXRFl2MqU"
   },
   "source": [
    "There is one ‘country’ that is not really one, which is Antarctica. We'll remove this from the list here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e16tyLIgtCaG"
   },
   "outputs": [],
   "source": [
    "countries = countries.drop(\"ATA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMuvKbHMGQWN"
   },
   "source": [
    "Finally, we draw the chart using Altair's `mark_geoshape()` method. The distribution of densities is highly skewed, due to very small countries with relatively high population numbers, such as Monaco. To spread out the low and high density values we use a logarithmic scale and set the domain between 1 and 1000. Note that the domain has to end in a multiple of the base, which is by default 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ouYhA92YsfO5"
   },
   "outputs": [],
   "source": [
    "alt.Chart(countries).mark_geoshape().encode(\n",
    "    color=alt.Color('density', scale=alt.Scale(type=\"log\", domain=[1,1000] )),\n",
    "    tooltip=['name', 'areaInSqKm', 'population', 'density']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgrZIXSkwX0v"
   },
   "source": [
    "The map is shown in the default Mercator projection, which particularly distorts the area sizes of North America, Europe and Russia in contrast to Africa, Southern Asia and parts of South America.\n",
    "\n",
    "💡 *You can change the projection used above to one that does not distort area sizes as much ([see this list for options](https://vega.github.io/vega-lite/docs/projection.html#projection-types)).* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNSgGB5i1_M8"
   },
   "source": [
    "## Your Turn\n",
    "\n",
    "**Q1 (10 points).** Create a visualization with Austin's neighborhoods overlayed with Austin's libraries. The tool tip should provide necessary information to identify each neighborhood and library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2wExb-ca1_M8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2 (5 points).** Do you think the open data source for Austin's libraries is reliable? Why or why not? Answer in the Markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3 (10 points).** Add the location of all the trees in Austin (according to Open Street Map) to the visualization you just created in Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_bg-6pB1_M8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4 (10 points).** Create a global population density choropleth with the Albers map projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgMHkosQ1_M8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IELEzpLaViOM"
   },
   "source": [
    "## Sources\n",
    "\n",
    "Tutorials & Documentation\n",
    "- [Specifying Geospatial Data in Altair — Altair 4.1.0 documentation](https://altair-viz.github.io/user_guide/data.html#geospatial-data)\n",
    "- [GeoPandas](https://geopandas.org)\n",
    "- [OSMPythonTools](https://github.com/mocnik-science/osm-python-tools)\n",
    "\n",
    "Data\n",
    "- [OpenStreetMap](https://www.openstreetmap.org/)\n",
    "- [GeoNames](https://www.geonames.org)\n",
    "- [Data.gov](https://catalog.data.gov/dataset/public-school-locations-current)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Geovisualization.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
